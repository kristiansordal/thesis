\chapter{Results} \label{results}

\section{Theoretical Maximum}
As has been established, the maximum performance scales with the available memory bandwidth of the system, and not with the amount of processes used. For SpMV, a total of 6 bytes are read per FLOP, which means that the theoretical maximum is given by \ref{eq:theoretical_max}. This is under the assumption that all resources on the system is dedicated to the SpMV operation, which is not the case in reality. At most, somewhere in the neighbourhood of 80\% of the systems resources can be expected to be utilized.

\begin{equation}
\text{Maximum Theoretical Performance} = \frac{\text{Memory bandwidth}}{6}
\label{eq:theoretical_max}
\end{equation}


\section{Matrices}
For the results presented in the following sections, the matrices shown in Figure \ref{fig:matricesused} were selected as they are in general well-structure and symmetrical. 

\begin{figure}[H]
  \centering
  \captionsetup[sub]{font=tiny, textfont=tiny}
  \setlength{\tabcolsep}{4pt} % adjust horizontal padding between columns
  \begin{tabular}{cccc}
      \subcaptionbox{\tiny{bone010}\label{fig:bone010}}{%
      \includegraphics[width=0.23\textwidth]{bone010.png}%
    } &
    \subcaptionbox{\tiny{af\_shell10}\label{fig:af_shell10}}{%
      \includegraphics[width=0.23\textwidth]{af_shell10.png}%
    } &
    \subcaptionbox{\tiny{Serena}\label{fig:Serena}}{%
      \includegraphics[width=0.23\textwidth]{Serena.png}%
    } &
    \subcaptionbox{\tiny{Long\_Coup\_dt0}\label{fig:Long_Coup_dt0}}{%
      \includegraphics[width=0.23\textwidth]{Long_Coup_dt0.png}%
    } \\[6pt] % a little extra vertical gap
    \subcaptionbox{\tiny{dielFilterV3real}\label{fig:dielFilterV3real}}{%
      \includegraphics[width=0.23\textwidth]{dielFilterV3real.png}%
    } &
    \subcaptionbox{\tiny{Cube\_Coup\_dt0}\label{fig:Cube_Coup_dt0_1}}{%
      \includegraphics[width=0.23\textwidth]{Cube_Coup_dt0.png}%
    } &
    \subcaptionbox{\tiny{Bump\_2911}\label{fig:Bump_2911}}{%
      \includegraphics[width=0.23\textwidth]{Bump_2911.png}%
    } &
    \subcaptionbox{\tiny{nlpkkt200}\label{fig:nlpkkt200}}{%
      \includegraphics[width=0.23\textwidth]{nlpkkt200.png}%
    }
  \end{tabular}
  \caption{Matrices used to generate results.}
  \label{fig:matricesused}
\end{figure}

\begin{table}[H]
\begin{center}
\begin{tabular}[c]{|l|l|}
\hline
\textbf{Name}&\textbf{Purpose}  \\
\hline
bone010&Trabecular Bone Micro-Finite Element Model\\
\hline
af\_shell1&Sheet metal forming matrix\\
\hline
Serena&Gas reservoir simulation for \(CO_{2}\) sequestration\\
\hline
Long\_Coup\_dt0&3D coupled consolidation problem (geological formation)\\
\hline
dielFilterV3real&High-order vector finite element method in EM\\
\hline
Cube\_Coup\_dt0&3D coupled consolidation problem (3D cube)\\
\hline
Bump\_2911&3D geomechanical reservoir simulation\\
\hline
nlpkkt200&Symmetric indefinite KKT matrix\\
\hline
\end{tabular}
\end{center}
\end{table}


\section{Overview of Experiments}
The experiments that have been ran in order to obtain the results in the following thesis have made use of systems on the Experimental Infrastructure for Exploration of Exascale Computing (eX\(^{3}\)).
\medskip

For each experiment, every matrix has been put through 100 iterations of SpMV, and every communication strategy has been tested on different configurations. For the single node experiments, each communication strategy has been ran with the number of MPI ranks being doubled until every available physical core on the chip is assigned one MPI rank. For multi node experiments on single socketed nodes, one MPI rank is assigned to each rank, and shared memory parallelization has been used within each node. On dual socketed nodes, experiments placing one MPI rank per node and placing one MPI rank per socket have been ran. All programs have been compiled with \texttt{-march=native} and \texttt{-O3} compilation flags.

% \begin{table}[H]
%     \begin{center}
%         \begin{tabular}[c]{|p{3cm}|p{3cm}|p{3cm}|p{3cm}|}
%             \hline
%             &\textbf{\defq}&\textbf{\fpgaq}&\textbf{\romeq}  \\
%             \hline
%             No. of sockets&2&2&1  \\
%             \hline
%             No. of physical cores per socket&32&24&16  \\
%             \hline
%             No. of nodes&4&4&8  \\
%             \hline
%             Tested single node performance&Yes&No&No  \\
%             \hline
%             Single Node Ranks&\(1,2,4,8,16,32,64\)&N/A&N/A  \\
%             \hline
%         \end{tabular}
%     \end{center}
%     \caption{Configurations used on experiments}
% \end{table}

In the following presentation of the results, \ref{tab:commstratdesc} gives an overview of what the different strategies will be referred to, both when analyzing the results, and in the legends of the figures.

\begin{table}[H]
    \begin{center}
        \begin{tabular}[c]{|p{3cm}|p{9.5cm}|}
            \hline
             \textbf{Strategy name}& \textbf{Strategy Description}  \\
            \hline
             Strategy A&Exchanges entire local vector.  \\
            \hline
             Strategy B&Exchanges entire separator.  \\
            \hline
             Strategy C&Exchanges required separator.  \\
            \hline
             Strategy D&Exchanges required separator elements  \\
            \hline
             Strategy E&Exchanges required separator elements, memory scalable  \\
            \hline
        \end{tabular}
    \end{center}
    \label{tab:commstratdesc}
\end{table}

\section{\defq - Single Node Performance}
The results in this section illustrates the performance of the communication strategies when performed on a single node containing two \defq\phantom{a}chips.  
\input{defqsingle}
\medskip


% \inputdefqsingle.tex}
\section{(Rome16q) \romeq}
\input{romemulti.tex}

\section{(defq) \defq}
\section{(defq multi) \defq}
\input{defqmulti}



\input{CPUtable}

